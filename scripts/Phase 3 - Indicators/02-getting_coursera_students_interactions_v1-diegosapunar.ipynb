{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (7) Getting Coursera Students Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **author** = Diego Sapunar-Opazo\n",
    "* **copyright** = Copyright 2019, Thesis M.Sc. Diego Sapunar - Pontificia Universidad CatÃ³lica de Chile\n",
    "* **credits** = Diego Sapunar-Opazo, Ronald Perez, Mar Perez-Sanagustin, Jorge Maldonado-Mahauad\n",
    "* **maintainer** = Diego Sapunar-Opazo\n",
    "* **email** = dasapunar@uc.cl\n",
    "* **status** = Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scripts gets the Coursera Report, Coursera Gradebook and creates:\n",
    "\n",
    "Coursera_learning_path.csv\n",
    "\n",
    "(1) **num_alumno**, which corresponds to the internal face-to-face students' id and \n",
    "\n",
    "(2) **week**, which corresponds to the week\n",
    "\n",
    "(3) **session**, which corresponds to a study session\n",
    "\n",
    "(4) **timestamp**, which corresponds to the timestamp when the interaction was recorded\n",
    "\n",
    "(5) **interaction**, which corresponds to the type of interaction\n",
    "\n",
    "(6) **timespent**, which corresponds how long was that interaction in seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# datetime\n",
    "from datetime import datetime\n",
    "\n",
    "SESSION_LENGTH = 45 * 60 # in seconds\n",
    "\n",
    "WEEKS_METADATA = {\n",
    "                1: (datetime.strptime('2018-08-20 00:00:01.00', '%Y-%m-%d %H:%M:%S.%f'), \n",
    "                    datetime.strptime('2018-08-26 23:59:59.00', '%Y-%m-%d %H:%M:%S.%f')),\n",
    "                2: (datetime.strptime('2018-08-27 00:00:01.00', '%Y-%m-%d %H:%M:%S.%f'),\n",
    "                    datetime.strptime('2018-09-02 23:59:59.00', '%Y-%m-%d %H:%M:%S.%f')),\n",
    "                3: (datetime.strptime('2018-09-03 00:00:01.00', '%Y-%m-%d %H:%M:%S.%f'),\n",
    "                    datetime.strptime('2018-09-09 23:59:59.00', '%Y-%m-%d %H:%M:%S.%f')),\n",
    "                4: (datetime.strptime('2018-09-10 00:00:01.00', '%Y-%m-%d %H:%M:%S.%f'),\n",
    "                    datetime.strptime('2018-09-16 23:59:59.00', '%Y-%m-%d %H:%M:%S.%f')),\n",
    "                5: (datetime.strptime('2018-09-24 00:00:01.00', '%Y-%m-%d %H:%M:%S.%f'),\n",
    "                    datetime.strptime('2018-09-30 23:59:59.00', '%Y-%m-%d %H:%M:%S.%f')),\n",
    "                6: (datetime.strptime('2018-10-01 00:00:01.00', '%Y-%m-%d %H:%M:%S.%f'),\n",
    "                    datetime.strptime('2018-10-07 23:59:59.00', '%Y-%m-%d %H:%M:%S.%f')),\n",
    "                7: (datetime.strptime('2018-10-08 00:00:01.00', '%Y-%m-%d %H:%M:%S.%f'),\n",
    "                    datetime.strptime('2018-10-14 23:59:59.00', '%Y-%m-%d %H:%M:%S.%f')),\n",
    "                8: (datetime.strptime('2018-10-22 00:00:01.00', '%Y-%m-%d %H:%M:%S.%f'),\n",
    "                    datetime.strptime('2018-10-28 23:59:59.00', '%Y-%m-%d %H:%M:%S.%f')),\n",
    "                9: (datetime.strptime('2018-10-29 00:00:01.00', '%Y-%m-%d %H:%M:%S.%f'),\n",
    "                    datetime.strptime('2018-11-04 23:59:59.00', '%Y-%m-%d %H:%M:%S.%f')),\n",
    "                101: (datetime.strptime('2018-11-12 00:00:01.00', '%Y-%m-%d %H:%M:%S.%f'),\n",
    "                       datetime.strptime('2018-11-18 23:59:59.00', '%Y-%m-%d %H:%M:%S.%f')),\n",
    "                102: (datetime.strptime('2018-11-05 00:00:01.00', '%Y-%m-%d %H:%M:%S.%f'),\n",
    "                       datetime.strptime('2018-11-11 23:59:59.00', '%Y-%m-%d %H:%M:%S.%f')),\n",
    "                11: (datetime.strptime('2018-11-19 00:00:01.00', '%Y-%m-%d %H:%M:%S.%f'),\n",
    "                       datetime.strptime('2018-11-25 23:59:59.00', '%Y-%m-%d %H:%M:%S.%f')),\n",
    "                }    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    '''\n",
    "    Read a .csv file and convert it in a Pandas DataFrame.\n",
    "    \n",
    "    Input:\n",
    "    path - String: path where the .csv is located.\n",
    "    \n",
    "    Output:\n",
    "    Pandas DataFrame: .csv in the Pandas DataFrame format.\n",
    "    '''\n",
    "    \n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Preprocessing & Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocc_data(df, slices=False, columns_to_rename=False, datetime=False):\n",
    "    '''\n",
    "    From a dataframe on the fly, (1) get the necessary columns; (2) rename columns; and (3) clean data.\n",
    "    \n",
    "    Input: \n",
    "    df - Pandas DataFrame: dataframe to be cleaned.\n",
    "    columns_to_rename - Dict: Columns to rename, Key: original name, Value: new name.\n",
    "    datetime - List of Strings: List of the names of the columns to be datetime.\n",
    "    \n",
    "    Output:\n",
    "    df - Pandas DataFrame: the dataframe already cleaned.\n",
    "    '''\n",
    "    \n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    # slicing the columns, getting only the one that I need (num_alumno and seccion)\n",
    "    if slices:\n",
    "        df_cleaned = df_cleaned.iloc[:,slices]\n",
    "    \n",
    "    del df  # clean memory\n",
    "    \n",
    "    # rename columns\n",
    "    if columns_to_rename:\n",
    "        df_cleaned.rename(_columns_to_rename, \n",
    "                          inplace=True, \n",
    "                          axis=1)\n",
    "    \n",
    "    if datetime:\n",
    "        for cat in datetime:\n",
    "            \n",
    "            df_cleaned[cat] = pd.to_datetime(df_cleaned[cat], \n",
    "                                             format='%Y-%m-%d %H:%M:%S.%f')\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging(df1, df2, variable1, variable2):\n",
    "    '''\n",
    "    Merge df1 and df2 over the variable.\n",
    "    \n",
    "    Input:\n",
    "    df1 - Pandas DataFrame\n",
    "    df2 - Pandas DataFrame\n",
    "    variable - String: name of the column to use as pivot.\n",
    "    \n",
    "    Output:\n",
    "    Pandas DataFrame\n",
    "    '''\n",
    "    \n",
    "    # getting same types\n",
    "    df1[variable1] = df1[variable1].astype('str')\n",
    "    df2[variable2] = df2[variable2].astype('str')\n",
    "    \n",
    "    return pd.merge(left=df1, right=df2, left_on=variable1, right_on=variable2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_week(timestamp, sec, WEEKS_METADATA):\n",
    "    '''\n",
    "    Get the week that corresponds to the timestamp.\n",
    "    \n",
    "    Input:\n",
    "    timestamp - datetime: corresponds to the timestamp of the interaction\n",
    "    sec - int: corresponds to the section of the user\n",
    "    \n",
    "    Output:\n",
    "    week - int\n",
    "    '''\n",
    "    \n",
    "    for week in range(1,12):\n",
    "        if week == 10:\n",
    "            if sec == 1: week = 101\n",
    "            else: week = 102\n",
    "        \n",
    "        if (timestamp > WEEKS_METADATA[week][0]) and (timestamp <= WEEKS_METADATA[week][1]):\n",
    "            if week in [101, 102]: week = 10\n",
    "            return week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obtained(df_grades, lms_id, item_id):\n",
    "    '''\n",
    "    Get the timespant when the user get his better grade and if he pass or not that item.\n",
    "    \n",
    "    Input:\n",
    "    df_grades - pandas DataFrame: the dataframe with de grades.\n",
    "    lms_id - String: lms_id to be consulted.\n",
    "    item_id - String: item_id of the item to be evaluated.\n",
    "    \n",
    "    Output:\n",
    "    Tuple with the timestamp when the grade was obtained and if the student pass or don't the item\n",
    "    '''\n",
    "    \n",
    "    aux = df_grades[(df_grades['lms_id']==lms_id) & (df_grades['item_id']==item_id)]\n",
    "    if len(aux):\n",
    "        if item_id: return (aux.iloc[0][2], aux.iloc[0][3])\n",
    "        else: return (aux.iloc[0][2], aux.iloc[0][3])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interaction(item_id, item_state, videos, \n",
    "                    readings, quiz, items_completed_dic, \n",
    "                    item_ts, df_grades, lms_id):\n",
    "    '''\n",
    "    Return the type of the interaction of the item.\n",
    "    \n",
    "    Input:\n",
    "    item_id - String: item_id of the item to be evaluated.\n",
    "    item_state - int: state of the item to be evaluated.\n",
    "    videos - Series: list of videos.\n",
    "    readings - Series: list of readings.\n",
    "    quiz - Series: list of quizes.\n",
    "    items_completed - list of strings: list of the item_ids completed\n",
    "    item_ts - DateTime: the datetime of the item\n",
    "    \n",
    "    Output:\n",
    "    String with the type of interaction\n",
    "    '''\n",
    "    \n",
    "    items_completed = items_completed_dic[lms_id]\n",
    "    if item_id in videos.values:\n",
    "        if item_id in items_completed:\n",
    "            return 'Video-Lecture review'\n",
    "        elif item_state == 1:\n",
    "            return 'Video-Lecture begin'\n",
    "        else:  # completed\n",
    "            items_completed.append(item_id)\n",
    "            items_completed_dic[lms_id] = items_completed\n",
    "            return 'Video-Lecture completed'\n",
    "        \n",
    "    elif item_id in readings.values:\n",
    "        if item_id in items_completed:\n",
    "            return 'Reading review'\n",
    "        elif item_state == 1:\n",
    "            return 'Reading begin'\n",
    "        else:  # completed\n",
    "            items_completed.append(item_id)\n",
    "            items_completed_dic[lms_id] = items_completed\n",
    "            return 'Reading completed'\n",
    "        \n",
    "    else:  # quiz\n",
    "        if item_id in items_completed:\n",
    "            return 'Assessment review'\n",
    "        else:\n",
    "            # get grade_obtained_ts\n",
    "            aux = get_obtained(df_grades, lms_id, item_id)\n",
    "            if aux:\n",
    "                grade_obtained_ts, pass_flag = aux\n",
    "                if item_ts < grade_obtained_ts:\n",
    "                    return 'Assessment try'\n",
    "                elif pass_flag:  # pass\n",
    "                    items_completed.append(item_id)\n",
    "                    items_completed_dic[lms_id] = items_completed\n",
    "                    return 'Assessment pass'\n",
    "                else: \n",
    "                    return 'Assessment try'\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sess(timespent, session_dic, num_alumno, week, next_week, df):\n",
    "    '''\n",
    "    Fix the timespent and add sess\n",
    "    \n",
    "    Input:\n",
    "    timespent - float: the original timespent in the interaction\n",
    "    session_dic - dic: a dic with key the num_alumno and as a key other dic with key week and value the number of sessions in that week\n",
    "    num_alumno - string\n",
    "    week - int\n",
    "    next_week - int: if the next interaction is in another week (works as a boolean)\n",
    "    df - pandas Dataframe: with the information of the interactions\n",
    "    \n",
    "    Output:\n",
    "    a dic with the timespent fixed and the session of that interaction\n",
    "    '''\n",
    "    \n",
    "    if timespent < 0:\n",
    "        \n",
    "        return {'timespent_real': 0, \n",
    "                'session':session_dic[num_alumno][week]}\n",
    "    elif timespent > SESSION_LENGTH:\n",
    "        if next_week:\n",
    "            pass\n",
    "        else:\n",
    "            session_dic[num_alumno][week] += 1\n",
    "        return {'timespent_real': get_mean_week(num_alumno, week, df), \n",
    "                'session':session_dic[num_alumno][week]}\n",
    "    \n",
    "    else:\n",
    "        return {'timespent_real': timespent, \n",
    "                'session':session_dic[num_alumno][week]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_week(num_alumno, week, df):\n",
    "    '''\n",
    "    Get the mean timespent in the week\n",
    "    \n",
    "    Input:\n",
    "    num_alumno - String: student's id\n",
    "    week - int: week\n",
    "    df - pandas Dataframe: data to query\n",
    "    \n",
    "    Output\n",
    "    float: mean.\n",
    "    '''\n",
    "    \n",
    "    return (df[(df['timespent'] > 0) & (df['timespent'] < SESSION_LENGTH) & (df['num_alumno'] == num_alumno) & (df['week'] == week)])['timespent'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(df, path):\n",
    "    '''\n",
    "    Export df in .csv fole to the path.\n",
    "    \n",
    "    Input:\n",
    "    df - Pandas DataFrame: dataframe to be exported.\n",
    "    path - String: path where the .csv will be exported.\n",
    "    '''\n",
    "    \n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4.1: Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_progress_path = '../../data/raw_data/coursera/coursera_logs/course_progress.csv'\n",
    "df_progress = read_data(_progress_path)\n",
    "\n",
    "_columns_to_rename = {\n",
    "    'course_item_id': 'item_id',\n",
    "    'ucchile_user_id': 'lms_id',\n",
    "    'course_item_grade_verified': 'item_grade',\n",
    "    'course_progress_state_type_id': 'item_state',\n",
    "    'course_progress_ts': 'item_timestamp'\n",
    "}\n",
    "\n",
    "df_progress = preprocc_data(df_progress, \n",
    "                            slices=[i for i in range(1, len(df_progress.columns))], \n",
    "                            columns_to_rename=_columns_to_rename, \n",
    "                            datetime=['item_timestamp'])\n",
    "                           \n",
    "\n",
    "_students_lms_id_path = '../../data/clean_data/students_lms_id.csv'\n",
    "df_students_lms_id = read_data(_students_lms_id_path)\n",
    "lms_list = df_students_lms_id['lms_id']\n",
    "\n",
    "_items_path = '../../data/clean_data/coursera_items.csv'\n",
    "df_items = read_data(_items_path)\n",
    "mask_videos = df_items['item_type_id'] == 1\n",
    "videos = df_items[mask_videos]['item_id']\n",
    "mask_readings = df_items['item_type_id'] == 3\n",
    "readings = df_items[mask_readings]['item_id']\n",
    "mask_quiz = (df_items['item_type_id'] == 6) | (df_items['item_type_id'] == 106)\n",
    "quiz = df_items[mask_quiz]['item_id']\n",
    "del df_items\n",
    "\n",
    "_grades_path = '../../data/raw_data/coursera/coursera_logs/course_item_grades.csv'\n",
    "df_grades = read_data(_grades_path)\n",
    "\n",
    "_columns_to_rename = {\n",
    "    'course_item_id': 'item_id',\n",
    "    'ucchile_user_id': 'lms_id',\n",
    "    'course_item_passing_state_id': 'item_state',\n",
    "    'course_item_grade_ts': 'item_timestamp'\n",
    "}\n",
    "\n",
    "df_grades = preprocc_data(df_grades, \n",
    "                          slices=[i for i in range(1,5)],\n",
    "                          columns_to_rename=_columns_to_rename,\n",
    "                          datetime=['item_timestamp'])\n",
    "\n",
    "_students_sec = '../../data/clean_data/students_sec.csv'\n",
    "df_students_sec = read_data(_students_sec)\n",
    "\n",
    "items_completed_dic = {str(i):[] for i in lms_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4.2: Filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping in progress our users\n",
    "mask_filtering_lms_id = df_progress['lms_id'].isin(lms_list)\n",
    "df_progress = df_progress.loc[mask_filtering_lms_id].copy()\n",
    "\n",
    "# Keeping in progress only the elements that I'm working on!\n",
    "mask_filtering_element = (df_progress['item_id'].isin(videos)) | (df_progress['item_id'].isin(readings)) | (df_progress['item_id'].isin(quiz))\n",
    "df_progress = df_progress.loc[mask_filtering_element].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4.3: Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding num_alumno\n",
    "df_progress = merging(df_progress, df_students_lms_id, 'lms_id', 'lms_id')\n",
    "\n",
    "# Adding sec\n",
    "df_progress = merging(df_progress, df_students_sec, 'num_alumno', 'num_alumno')\n",
    "\n",
    "# sorting values\n",
    "df_progress.sort_values(['lms_id', 'item_timestamp'], inplace=True)\n",
    "\n",
    "# Adding timespent in progress\n",
    "df_progress['timespent'] = df_progress['item_timestamp'].shift(-1) - df_progress['item_timestamp']\n",
    "df_progress['timespent'] = df_progress.apply(lambda x: x['timespent'].total_seconds(),axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4.4: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_students_interactions = pd.DataFrame()\n",
    "\n",
    "df_students_interactions['num_alumno'] = (df_progress['num_alumno']).copy()\n",
    "\n",
    "df_students_interactions['week'] = df_progress.apply(lambda x: get_week(x['item_timestamp'], x['sec'], WEEKS_METADATA), axis=1)\n",
    "\n",
    "df_students_interactions['timestamp'] = (df_progress['item_timestamp']).copy()\n",
    "\n",
    "df_students_interactions['interaction'] = df_progress.apply(lambda x: get_interaction(item_id=x['item_id'],\n",
    "                                                                                      item_state=x['item_state'],\n",
    "                                                                                      videos=videos,\n",
    "                                                                                      readings=readings,\n",
    "                                                                                      quiz=quiz,\n",
    "                                                                                      items_completed_dic=items_completed_dic,\n",
    "                                                                                      item_ts=x['item_timestamp'], \n",
    "                                                                                      df_grades=df_grades, \n",
    "                                                                                      lms_id=x['lms_id']), \n",
    "                                                            axis=1)\n",
    "\n",
    "df_students_interactions['timespent'] = (df_progress['timespent']).copy()\n",
    "\n",
    "\n",
    "df_students_interactions['next_week'] = df_students_interactions['week'].shift(-1) - df_students_interactions['week']\n",
    "\n",
    "df_students_interactions.dropna(inplace=True)\n",
    "\n",
    "session_dic = {str(i):{j:1 for j in range(1,12)} for i in df_students_interactions.num_alumno}\n",
    "df_students_interactions = df_students_interactions.merge(df_students_interactions.apply(lambda x: pd.Series(add_sess(x['timespent'], session_dic, \n",
    "                                                        x['num_alumno'], x['week'], x['next_week'], df_students_interactions)),axis=1), left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4.4: Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_export_path_students_interactions = '../../data/final_data/coursera_students_interactions_nueva.csv'\n",
    "\n",
    "export_data(df_students_interactions.drop(['timespent', 'next_week'], axis=1).rename({'timespent_real':'timespent'}, axis=1), _export_path_students_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data(aux, _export_path_students_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_alumno             object\n",
       "week                  float64\n",
       "timestamp      datetime64[ns]\n",
       "interaction            object\n",
       "timespent             float64\n",
       "session               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
