{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Cleaning Coursera Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **author** = Diego Sapunar-Opazo\n",
    "* **copyright** = Copyright 2019, Thesis M.Sc. Diego Sapunar - Pontificia Universidad Cat√≥lica de Chile\n",
    "* **credits** = Diego Sapunar-Opazo, Ronald Perez, Mar Perez-Sanagustin, Jorge Maldonado-Mahauad\n",
    "* **maintainer** = Diego Sapunar-Opazo\n",
    "* **email** = dasapunar@uc.cl\n",
    "* **status** = Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scripts gets Coursera's Report and takes the necessary metadata for the analysis. Also the information from the f2f component is used, such as, matching the weeks.\n",
    "\n",
    "The files created will be:\n",
    "\n",
    "coursera_weeks.csv\n",
    "\n",
    "(1) **week_id**, which corresponds to Coursera's internal id for a week\n",
    "\n",
    "(2) **week**, which corresponds to the week related to the face-to-face component\n",
    "\n",
    "coursera_lessons.csv\n",
    "\n",
    "(1) **lesson_id**, which corresponds to Coursera's internal id for a lesson\n",
    "\n",
    "(2) **week**, which corresponds to the week related to the face-to-face component\n",
    "\n",
    "coursera_items.csv\n",
    "\n",
    "(1) **item_id**, which corresponds to Coursera's internal id for a item\n",
    "\n",
    "(2) **item_type_id**, which corresponds to Coursera's internal id for a item's type\n",
    "\n",
    "(3) **week**, which corresponds to the week related to the face-to-face component\n",
    "\n",
    "coursera_weeks_items.csv: The one above aggregated\n",
    "\n",
    "(1) **week**, which corresponds to the week related to the face-to-face component\n",
    "\n",
    "(2) **videos**, q of videos of that week\n",
    "\n",
    "(3) **readings**, q of readings of that week\n",
    "\n",
    "(4) **quiz**, q of quiz of that week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    '''\n",
    "    Read a .csv file and convert it in a Pandas DataFrame.\n",
    "    \n",
    "    Input:\n",
    "    path - String: path where the .csv is located.\n",
    "    \n",
    "    Output:\n",
    "    Pandas DataFrame: .csv in the Pandas DataFrame format.\n",
    "    '''\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocc_data(df, slices=False, columns_to_rename=False, categories=False):\n",
    "    '''\n",
    "    From a dataframe on the fly, (1) get the necessary columns; (2) rename columns; and (3) clean data.\n",
    "    \n",
    "    Input: \n",
    "    df - Pandas DataFrame: dataframe to be cleaned.\n",
    "    columns_to_rename - Dict: Columns to rename, Key: original name, Value: new name.\n",
    "    categories - List of Strings: List of the names of the columns to be category type. If you renamed some columns, should be the new names.\n",
    "    \n",
    "    Output:\n",
    "    df - Pandas DataFrame: the dataframe already cleaned.\n",
    "    '''\n",
    "    \n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    # slicing the columns, getting only the one that I need (num_alumno and seccion)\n",
    "    if slices:\n",
    "        df_cleaned = df_cleaned.iloc[:,slices]\n",
    "    \n",
    "    del df  # clean memory\n",
    "    \n",
    "    # rename columns\n",
    "    if columns_to_rename:\n",
    "        df_cleaned.rename(_columns_to_rename, \n",
    "                          inplace=True, \n",
    "                          axis=1)\n",
    "    \n",
    "    if categories:\n",
    "        for cat in categories:\n",
    "            # creating categories\n",
    "            df_cleaned[cat] = df_cleaned[cat].astype('category')\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging(df1, df2, variable1, variable2):\n",
    "    '''\n",
    "    Merge df1 and df2 over the variable.\n",
    "    \n",
    "    Input:\n",
    "    df1 - Pandas DataFrame\n",
    "    df2 - Pandas DataFrame\n",
    "    variable - String: name of the column to use as pivot.\n",
    "    \n",
    "    Output:\n",
    "    Pandas DataFrame\n",
    "    '''\n",
    "\n",
    "    df1.dropna(inplace=True)\n",
    "    df2.dropna(inplace=True)\n",
    "    \n",
    "    # getting same types\n",
    "    df1[variable1] = df1[variable1].astype('str')\n",
    "    df2[variable2] = df2[variable2].astype('str')\n",
    "    \n",
    "    return pd.merge(left=df1, right=df2, left_on=variable1, right_on=variable2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(df, path, columns_to_drop=False):\n",
    "    '''\n",
    "    Export df in .csv file to the path.\n",
    "    \n",
    "    Input:\n",
    "    df - Pandas DataFrame: dataframe to be exported.\n",
    "    path - String: path where the .csv will be exported.\n",
    "    '''\n",
    "    if columns_to_drop:\n",
    "        df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "        \n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "_branch = 'branch~JZ-LmYwtEeijexJtZffLBA'\n",
    "\n",
    "# WEEKS\n",
    "_weeks_path = '../data/original_data/coursera/CourseraReport/course_branch_modules.csv'\n",
    "df_modules = read_data(_weeks_path)\n",
    "\n",
    "mask_modules_branch = df_modules['course_branch_id'] == _branch\n",
    "df_modules = df_modules.loc[mask_modules_branch]\n",
    "\n",
    "_columns_to_rename = {\n",
    "    'course_module_id': 'week_id',\n",
    "    'course_branch_module_order': 'week'\n",
    "}\n",
    "df_weeks = preprocc_data(df_modules, slices=[1,2], columns_to_rename=_columns_to_rename)\n",
    "# joining weeks and wrangling to match with the course design\n",
    "df_weeks['week'] = df_weeks['week'] + 1\n",
    "\n",
    "values_to_replace = {\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 3,\n",
    "    5: 4,\n",
    "    6: 5,\n",
    "    7: 6,\n",
    "    8: 7,\n",
    "    9: 8,\n",
    "    10: 9,\n",
    "    11: 10,\n",
    "    12: 11\n",
    "}\n",
    "df_weeks.replace(values_to_replace, inplace=True)\n",
    "export_data(df_weeks, '../data/final_model/coursera_weeks.csv')\n",
    "del df_modules\n",
    "\n",
    "# LESSONS\n",
    "_lessons_path = '../data/original_data/coursera/CourseraReport/course_branch_lessons.csv'\n",
    "df_lessons = read_data(_lessons_path)\n",
    "\n",
    "mask_lessons_branch = df_lessons['course_branch_id'] == _branch\n",
    "df_lessons = df_lessons.loc[mask_lessons_branch]\n",
    "\n",
    "df_lessons = merging(df_lessons, df_weeks, 'course_module_id', 'week_id')\n",
    "\n",
    "_columns_to_rename = {\n",
    "    'course_lesson_id': 'lesson_id'\n",
    "}\n",
    "df_lessons = preprocc_data(df_lessons, slices=[1, 6], columns_to_rename=_columns_to_rename)\n",
    "\n",
    "export_data(df_lessons, '../data/final_model/coursera_lessons.csv')\n",
    "\n",
    "# ITEMS\n",
    "# _items_path = '../data/original_data/coursera/CourseraReport/course_branch_items.csv'\n",
    "_items_path = '../data/original_data/coursera/CourseraReport/course_branch_items.csv'\n",
    "\n",
    "df_items = pd.read_csv(_items_path, usecols=[i for i in range(5)])\n",
    "\n",
    "mask_items_branch = df_items['course_branch_id'] == _branch\n",
    "df_items = df_items.loc[mask_items_branch]\n",
    "\n",
    "df_items = merging(df_items, df_lessons, 'course_lesson_id', 'lesson_id')\n",
    "del df_lessons\n",
    "\n",
    "_columns_to_rename = {\n",
    "    'course_item_id': 'item_id',\n",
    "    'course_item_type_id': 'item_type_id'\n",
    "}\n",
    "df_items = preprocc_data(df_items, slices=[1, 4, 5, 6], columns_to_rename=_columns_to_rename)\n",
    "df_items.replace({106: 6}, inplace=True)\n",
    "export_data(df_items, '../data/final_model/coursera_items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating coursera_weeks_items.csv\n",
    "aux = df_items.groupby(['week','item_type_id']).count()\n",
    "\n",
    "n = pd.pivot_table(aux,\n",
    "              index='week',\n",
    "              columns='item_type_id',\n",
    "              values='lesson_id',\n",
    "              aggfunc=np.sum)\n",
    "export_data(n.reset_index().\n",
    "            rename({1:'videos', 3:'readings',6:'quiz'}, \n",
    "                                   axis=1), '../data/final_model/coursera_weeks_items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
